{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import PointStruct, VectorParams, Distance\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "driver = GraphDatabase.driver(\"bolt://localhost:7687\", auth=(\"neo4j\", \"12345678\"))\n",
    "\n",
    "def get_related_keywords(keyword):\n",
    "    query = \"\"\"\n",
    "    MATCH (n)\n",
    "    WHERE toLower(n.name) CONTAINS toLower($keyword)\n",
    "    MATCH (n)--(related)\n",
    "    RETURN DISTINCT related.name AS keyword, labels(related) AS type\n",
    "    \"\"\"\n",
    "    with driver.session() as session:\n",
    "        result = session.run(query, keyword=keyword)\n",
    "        return [record[\"keyword\"] for record in result]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pompe Ã  chaleur', 'Plancher chauffant', 'Isolation thermique']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(get_related_keywords(\"chauffage\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension: 768\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\"CHUNKS\\\\file_chunks.csv\") \n",
    "model = SentenceTransformer(\"dangvantuan/sentence-camembert-base\")\n",
    "\n",
    "# Let's quickly check the embedding dimension:\n",
    "dummy_vector = model.encode(\"texte de test\")\n",
    "dim = len(dummy_vector)  # This will be used in Qdrant's vector params\n",
    "print(f\"Embedding dimension: {dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amine\\AppData\\Local\\Temp\\ipykernel_30736\\3057219795.py:6: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  client.recreate_collection(\n",
      "11630it [03:10, 60.97it/s]\n"
     ]
    },
    {
     "ename": "UnexpectedResponse",
     "evalue": "Unexpected Response: 400 (Bad Request)\nRaw response content:\nb'{\"status\":{\"error\":\"Payload error: JSON payload (196289181 bytes) is larger than allowed (limit: 33554432 bytes).\"},\"time\":0.0}'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnexpectedResponse\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 35\u001b[0m\n\u001b[0;32m     26\u001b[0m     points_to_upsert\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m     27\u001b[0m         PointStruct(\n\u001b[0;32m     28\u001b[0m             \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39mpoint_id,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m         )\n\u001b[0;32m     32\u001b[0m     )\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Upsert in batches (here everything at once for brevity):\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpoints_to_upsert\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpsert complete. Stored embeddings in Qdrant.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\conda\\envs\\ds_env\\lib\\site-packages\\qdrant_client\\qdrant_client.py:1567\u001b[0m, in \u001b[0;36mQdrantClient.upsert\u001b[1;34m(self, collection_name, points, wait, ordering, shard_key_selector, **kwargs)\u001b[0m\n\u001b[0;32m   1564\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m         points \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embed_models(points, is_query\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m-> 1567\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mupsert(\n\u001b[0;32m   1568\u001b[0m     collection_name\u001b[38;5;241m=\u001b[39mcollection_name,\n\u001b[0;32m   1569\u001b[0m     points\u001b[38;5;241m=\u001b[39mpoints,\n\u001b[0;32m   1570\u001b[0m     wait\u001b[38;5;241m=\u001b[39mwait,\n\u001b[0;32m   1571\u001b[0m     ordering\u001b[38;5;241m=\u001b[39mordering,\n\u001b[0;32m   1572\u001b[0m     shard_key_selector\u001b[38;5;241m=\u001b[39mshard_key_selector,\n\u001b[0;32m   1573\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1574\u001b[0m )\n",
      "File \u001b[1;32md:\\conda\\envs\\ds_env\\lib\\site-packages\\qdrant_client\\qdrant_remote.py:1908\u001b[0m, in \u001b[0;36mQdrantRemote.upsert\u001b[1;34m(self, collection_name, points, wait, ordering, shard_key_selector, **kwargs)\u001b[0m\n\u001b[0;32m   1905\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(points, models\u001b[38;5;241m.\u001b[39mBatch):\n\u001b[0;32m   1906\u001b[0m     points \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mPointsBatch(batch\u001b[38;5;241m=\u001b[39mpoints, shard_key\u001b[38;5;241m=\u001b[39mshard_key_selector)\n\u001b[1;32m-> 1908\u001b[0m http_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopenapi_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoints_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupsert_points\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1909\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1910\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1911\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpoint_insert_operations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpoints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1912\u001b[0m \u001b[43m    \u001b[49m\u001b[43mordering\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mordering\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1913\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mresult\n\u001b[0;32m   1914\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m http_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpsert returned None result\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1915\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m http_result\n",
      "File \u001b[1;32md:\\conda\\envs\\ds_env\\lib\\site-packages\\qdrant_client\\http\\api\\points_api.py:987\u001b[0m, in \u001b[0;36mSyncPointsApi.upsert_points\u001b[1;34m(self, collection_name, wait, ordering, point_insert_operations)\u001b[0m\n\u001b[0;32m    977\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupsert_points\u001b[39m(\n\u001b[0;32m    978\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    979\u001b[0m     collection_name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    982\u001b[0m     point_insert_operations: m\u001b[38;5;241m.\u001b[39mPointInsertOperations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    983\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m m\u001b[38;5;241m.\u001b[39mInlineResponse2006:\n\u001b[0;32m    984\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    985\u001b[0m \u001b[38;5;124;03m    Perform insert + updates on points. If point with given ID already exists - it will be overwritten.\u001b[39;00m\n\u001b[0;32m    986\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 987\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_for_upsert_points\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    988\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    989\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    990\u001b[0m \u001b[43m        \u001b[49m\u001b[43mordering\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mordering\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    991\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpoint_insert_operations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpoint_insert_operations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    992\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\conda\\envs\\ds_env\\lib\\site-packages\\qdrant_client\\http\\api\\points_api.py:512\u001b[0m, in \u001b[0;36m_PointsApi._build_for_upsert_points\u001b[1;34m(self, collection_name, wait, ordering, point_insert_operations)\u001b[0m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m headers:\n\u001b[0;32m    511\u001b[0m     headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 512\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtype_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInlineResponse2006\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPUT\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/collections/\u001b[39;49m\u001b[38;5;132;43;01m{collection_name}\u001b[39;49;00m\u001b[38;5;124;43m/points\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\conda\\envs\\ds_env\\lib\\site-packages\\qdrant_client\\http\\api_client.py:89\u001b[0m, in \u001b[0;36mApiClient.request\u001b[1;34m(self, type_, method, url, path_params, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     88\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mbuild_request(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\conda\\envs\\ds_env\\lib\\site-packages\\qdrant_client\\http\\api_client.py:112\u001b[0m, in \u001b[0;36mApiClient.send\u001b[1;34m(self, request, type_)\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    111\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ResponseHandlingException(e)\n\u001b[1;32m--> 112\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m UnexpectedResponse\u001b[38;5;241m.\u001b[39mfor_response(response)\n",
      "\u001b[1;31mUnexpectedResponse\u001b[0m: Unexpected Response: 400 (Bad Request)\nRaw response content:\nb'{\"status\":{\"error\":\"Payload error: JSON payload (196289181 bytes) is larger than allowed (limit: 33554432 bytes).\"},\"time\":0.0}'"
     ]
    }
   ],
   "source": [
    "# Adjust host/port if Qdrant is elsewhere:\n",
    "client = QdrantClient(url=\"http://localhost:6333\")  # or QdrantClient(\"localhost\", port=6333)\n",
    "\n",
    "# Create or recreate a collection\n",
    "collection_name = \"PROJET_RCRA2\"\n",
    "client.recreate_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=VectorParams(size=dim, distance=Distance.COSINE)\n",
    ")\n",
    "\n",
    "# Now, embed and upsert each CSV chunk as a separate point in Qdrant\n",
    "points_to_upsert = []\n",
    "for idx, row in tqdm(df.iterrows()):\n",
    "    text_chunk = row[\"chunk\"]\n",
    "    file_id = row[\"file\"]  # might be useful metadata\n",
    "    vector = model.encode(text_chunk)\n",
    "\n",
    "    # Create a unique ID for each chunk row\n",
    "    point_id = idx  \n",
    "    payload = {\n",
    "        \"file\": file_id, \n",
    "        \"chunk\": text_chunk\n",
    "    }\n",
    "\n",
    "    # Construct a PointStruct\n",
    "    points_to_upsert.append(\n",
    "        PointStruct(\n",
    "            id=point_id,\n",
    "            vector=vector.tolist(),\n",
    "            payload=payload\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â Uploaded batch 0 to 100\n",
      "â Uploaded batch 100 to 200\n",
      "â Uploaded batch 200 to 300\n",
      "â Uploaded batch 300 to 400\n",
      "â Uploaded batch 400 to 500\n",
      "â Uploaded batch 500 to 600\n",
      "â Uploaded batch 600 to 700\n",
      "â Uploaded batch 700 to 800\n",
      "â Uploaded batch 800 to 900\n",
      "â Uploaded batch 900 to 1000\n",
      "â Uploaded batch 1000 to 1100\n",
      "â Uploaded batch 1100 to 1200\n",
      "â Uploaded batch 1200 to 1300\n",
      "â Uploaded batch 1300 to 1400\n",
      "â Uploaded batch 1400 to 1500\n",
      "â Uploaded batch 1500 to 1600\n",
      "â Uploaded batch 1600 to 1700\n",
      "â Uploaded batch 1700 to 1800\n",
      "â Uploaded batch 1800 to 1900\n",
      "â Uploaded batch 1900 to 2000\n",
      "â Uploaded batch 2000 to 2100\n",
      "â Uploaded batch 2100 to 2200\n",
      "â Uploaded batch 2200 to 2300\n",
      "â Uploaded batch 2300 to 2400\n",
      "â Uploaded batch 2400 to 2500\n",
      "â Uploaded batch 2500 to 2600\n",
      "â Uploaded batch 2600 to 2700\n",
      "â Uploaded batch 2700 to 2800\n",
      "â Uploaded batch 2800 to 2900\n",
      "â Uploaded batch 2900 to 3000\n",
      "â Uploaded batch 3000 to 3100\n",
      "â Uploaded batch 3100 to 3200\n",
      "â Uploaded batch 3200 to 3300\n",
      "â Uploaded batch 3300 to 3400\n",
      "â Uploaded batch 3400 to 3500\n",
      "â Uploaded batch 3500 to 3600\n",
      "â Uploaded batch 3600 to 3700\n",
      "â Uploaded batch 3700 to 3800\n",
      "â Uploaded batch 3800 to 3900\n",
      "â Uploaded batch 3900 to 4000\n",
      "â Uploaded batch 4000 to 4100\n",
      "â Uploaded batch 4100 to 4200\n",
      "â Uploaded batch 4200 to 4300\n",
      "â Uploaded batch 4300 to 4400\n",
      "â Uploaded batch 4400 to 4500\n",
      "â Uploaded batch 4500 to 4600\n",
      "â Uploaded batch 4600 to 4700\n",
      "â Uploaded batch 4700 to 4800\n",
      "â Uploaded batch 4800 to 4900\n",
      "â Uploaded batch 4900 to 5000\n",
      "â Uploaded batch 5000 to 5100\n",
      "â Uploaded batch 5100 to 5200\n",
      "â Uploaded batch 5200 to 5300\n",
      "â Uploaded batch 5300 to 5400\n",
      "â Uploaded batch 5400 to 5500\n",
      "â Uploaded batch 5500 to 5600\n",
      "â Uploaded batch 5600 to 5700\n",
      "â Uploaded batch 5700 to 5800\n",
      "â Uploaded batch 5800 to 5900\n",
      "â Uploaded batch 5900 to 6000\n",
      "â Uploaded batch 6000 to 6100\n",
      "â Uploaded batch 6100 to 6200\n",
      "â Uploaded batch 6200 to 6300\n",
      "â Uploaded batch 6300 to 6400\n",
      "â Uploaded batch 6400 to 6500\n",
      "â Uploaded batch 6500 to 6600\n",
      "â Uploaded batch 6600 to 6700\n",
      "â Uploaded batch 6700 to 6800\n",
      "â Uploaded batch 6800 to 6900\n",
      "â Uploaded batch 6900 to 7000\n",
      "â Uploaded batch 7000 to 7100\n",
      "â Uploaded batch 7100 to 7200\n",
      "â Uploaded batch 7200 to 7300\n",
      "â Uploaded batch 7300 to 7400\n",
      "â Uploaded batch 7400 to 7500\n",
      "â Uploaded batch 7500 to 7600\n",
      "â Uploaded batch 7600 to 7700\n",
      "â Uploaded batch 7700 to 7800\n",
      "â Uploaded batch 7800 to 7900\n",
      "â Uploaded batch 7900 to 8000\n",
      "â Uploaded batch 8000 to 8100\n",
      "â Uploaded batch 8100 to 8200\n",
      "â Uploaded batch 8200 to 8300\n",
      "â Uploaded batch 8300 to 8400\n",
      "â Uploaded batch 8400 to 8500\n",
      "â Uploaded batch 8500 to 8600\n",
      "â Uploaded batch 8600 to 8700\n",
      "â Uploaded batch 8700 to 8800\n",
      "â Uploaded batch 8800 to 8900\n",
      "â Uploaded batch 8900 to 9000\n",
      "â Uploaded batch 9000 to 9100\n",
      "â Uploaded batch 9100 to 9200\n",
      "â Uploaded batch 9200 to 9300\n",
      "â Uploaded batch 9300 to 9400\n",
      "â Uploaded batch 9400 to 9500\n",
      "â Uploaded batch 9500 to 9600\n",
      "â Uploaded batch 9600 to 9700\n",
      "â Uploaded batch 9700 to 9800\n",
      "â Uploaded batch 9800 to 9900\n",
      "â Uploaded batch 9900 to 10000\n",
      "â Uploaded batch 10000 to 10100\n",
      "â Uploaded batch 10100 to 10200\n",
      "â Uploaded batch 10200 to 10300\n",
      "â Uploaded batch 10300 to 10400\n",
      "â Uploaded batch 10400 to 10500\n",
      "â Uploaded batch 10500 to 10600\n",
      "â Uploaded batch 10600 to 10700\n",
      "â Uploaded batch 10700 to 10800\n",
      "â Uploaded batch 10800 to 10900\n",
      "â Uploaded batch 10900 to 11000\n",
      "â Uploaded batch 11000 to 11100\n",
      "â Uploaded batch 11100 to 11200\n",
      "â Uploaded batch 11200 to 11300\n",
      "â Uploaded batch 11300 to 11400\n",
      "â Uploaded batch 11400 to 11500\n",
      "â Uploaded batch 11500 to 11600\n",
      "â Uploaded batch 11600 to 11630\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 100  # you can tweak this\n",
    "\n",
    "for i in range(0, len(points_to_upsert), BATCH_SIZE):\n",
    "    batch = points_to_upsert[i:i + BATCH_SIZE]\n",
    "    client.upsert(\n",
    "        collection_name=collection_name,\n",
    "        points=batch\n",
    "    )\n",
    "    print(f\"â Uploaded batch {i} to {i + len(batch)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_query_with_neo4j(user_query):\n",
    "    \"\"\"\n",
    "    Naive approach: split user query into tokens \n",
    "    and gather related keywords from Neo4j.\n",
    "    \"\"\"\n",
    "    tokens = user_query.lower().split()\n",
    "    all_expanded = set()\n",
    "    for token in tokens:\n",
    "        expansions = get_related_keywords(token)\n",
    "        all_expanded.update(expansions)\n",
    "    return list(all_expanded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_relevant_chunks(user_query, expansions, top_k=5):\n",
    "    \"\"\"\n",
    "    - Combine the user query with expansions\n",
    "    - Embed once\n",
    "    - Query Qdrant for the top_k most similar chunks\n",
    "    \"\"\"\n",
    "    if expansions:\n",
    "        expansion_text = \" \".join(expansions)\n",
    "        augmented_text = user_query + \" \" + expansion_text\n",
    "    else:\n",
    "        augmented_text = user_query\n",
    "    \n",
    "    query_vector = model.encode(augmented_text)\n",
    "\n",
    "    # Qdrant query\n",
    "    results = client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=query_vector.tolist(),\n",
    "        limit=top_k\n",
    "    )\n",
    "    \n",
    "    # 'results' will be a list of ScoredPoint objects\n",
    "    # Each contains 'payload' (with our stored chunk)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_query(user_query, top_k=5):\n",
    "    # 1) Expand user query with Neo4j\n",
    "    expansions = expand_query_with_neo4j(user_query)\n",
    "    # 2) Retrieve relevant chunks from Qdrant\n",
    "    docs = retrieve_relevant_chunks(user_query, expansions, top_k=top_k)\n",
    "    context_text = \"\"\n",
    "    for doc in docs:\n",
    "        payload = doc[1][0].payload\n",
    "        context_text += f\"Fichier: {payload['file']}\\nChunk: {payload['chunk']}\\n\\n\"\n",
    "    full_prompt = f\"\"\"\n",
    "    CONTEXTE:\n",
    "    {context_text}\n",
    "\n",
    "    QUESTION UTILISATEUR:\n",
    "    {user_query}\n",
    "\n",
    "    RÃPONSE ATTENDUE (en utilisant uniquement les informations ci-dessus) :\n",
    "    \"\"\"\n",
    "    return full_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ventilation', 'Chauffage', 'Isolation thermique', \"Membrane d'Ã©tanchÃ©itÃ©\", 'Chauffe-eau thermodynamique', 'RE2020', 'VMC double flux', 'Pompe Ã  chaleur', 'Plancher chauffant', 'Ãnergie renouvelable']\n"
     ]
    }
   ],
   "source": [
    "query = \"Quels sont les avantages dâutiliser une pompe Ã  chaleur avec un plancher chauffant ?\"\n",
    "query = expand_query(query, top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def query_ollama(prompt, model=\"llama3.2\"):\n",
    "    response = requests.post(\n",
    "        \"http://localhost:11434/api/generate\",\n",
    "        json={\n",
    "            \"model\": model,\n",
    "            \"prompt\": prompt,\n",
    "            \"stream\": False  # you can use True if you want streamed responses\n",
    "        }\n",
    "    )\n",
    "    data = response.json()\n",
    "    return data[\"response\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les avantages de l'utilisation d'une pompe Ã  chaleur avec un plancher chauffant sont :\n",
      "\n",
      "1. Chauffage thermodynamique basse tempÃ©rature : Cette technologie permet un chauffage efficace et respectueux de l'environnement, en utilisant les Ã©nergies renouvelables pour chauffer le plancher.\n",
      "2. Suppression du bouclage ECS (Ãquilibreur de Charge Solaire) : En utilisant une pompe Ã  chaleur avec un plancher chauffant, il n'est pas nÃ©cessaire d'installer un systÃ¨me de bouclage ECS, ce qui rÃ©duit les coÃ»ts et l'importance des dÃ©chets thermiques.\n",
      "3. Ãconomie d'Ã©nergie : Le chauffage basse tempÃ©rature peut rÃ©duire la consommation d'Ã©nergie pour chauffer le plancher, ce qui peut entraÃ®ner une rÃ©duction des factures de gaz ou d'Ã©lectricitÃ©.\n",
      "4. SÃ©curitÃ© et confort : L'utilisation d'une pompe Ã  chaleur avec un plancher chauffant peut amÃ©liorer la sÃ©curitÃ© et le confort dans les bÃ¢timents, en particulier pour les personnes Ã¢gÃ©es ou handicapÃ©es.\n",
      "5. Double ou triple service : Cette technologie permet de fournir plusieurs services (chauffage, Ã©clairage et climatisation) Ã  partir d'un mÃªme systÃ¨me, ce qui peut rÃ©duire la complexitÃ© du systÃ¨me et amÃ©liorer l'efficacitÃ© Ã©nergÃ©tique.\n",
      "\n",
      "Il est important de noter que ces avantages sont Ã©tayÃ©s par les informations fournies dans le fichier \"La Pompe Ã  chaleur, des solutions disponibles en habitat collectif.md\".\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result = query_ollama(query)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
